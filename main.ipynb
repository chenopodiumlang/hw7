{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# работа Суворовой Марии, 204\n",
    "(на всякий случай)\n",
    "\n",
    "Первое, что делаем - импортируем всё, что требуется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем файл train.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём функцию, которая подготавливает данные: лемматизирует предложения, считает tf-idf и масштабирует."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_model(data):\n",
    "    stops = stopwords.words(\"english\")\n",
    "    tfidf = TfidfVectorizer(\n",
    "        analyzer=\"word\",\n",
    "        stop_words=stops\n",
    "    )\n",
    "\n",
    "    data_preprocessed = []\n",
    "    for text in data:\n",
    "        tokens = wordpunct_tokenize(text)\n",
    "        text_lemmatized = \" \".join(\n",
    "            [morph.parse(item)[0].normal_form for item in tokens])\n",
    "        data_preprocessed.append(text_lemmatized)\n",
    "\n",
    "    data_tfidf = tfidf.fit_transform(data_preprocessed)\n",
    "    # data_tfidf = pd.DataFrame(data_tfidf.toarray())\n",
    "    # data_tfidf = data_tfidf[data_tfidf.columns[:76915]]\n",
    "    data_tfidf = data_tfidf[0:25000, 0:76096]\n",
    "\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    scaler.fit(data_tfidf)\n",
    "    scaler.transform(data_tfidf)\n",
    "    return data_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = prepare_data_for_model(train_df[\"text\"].tolist())\n",
    "y_tr = train_df[\"answer\"].tolist()\n",
    "X_te = prepare_data_for_model(test_df[\"text\"].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я выбрала метод KNN для данной задачи. Будут использоваться 5 соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = KNeighborsClassifier(n_neighbors=5)\n",
    "model5.fit(X_tr, y_tr)\n",
    "preds_te5 = model5.predict(X_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result5 = test_df[[\"id\"]].copy()\n",
    "result5[\"answer\"] = preds_te5\n",
    "\n",
    "result5.to_csv(\"result5.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
